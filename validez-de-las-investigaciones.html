<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Validez de las investigaciones | Diseño y Análisis de datos II</title>
  <meta name="description" content="Libro de DAD2" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Validez de las investigaciones | Diseño y Análisis de datos II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Libro de DAD2" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Validez de las investigaciones | Diseño y Análisis de datos II" />
  
  <meta name="twitter:description" content="Libro de DAD2" />
  

<meta name="author" content="Manuel Morales Ortiz" />


<meta name="date" content="2023-08-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lógica-de-la-investigación-científica.html"/>
<link rel="next" href="potencia-de-un-contraste.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Diseño y Análisis de Datos II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="introducción-a-los-procedimientos-de-investigación-en-psicología.html"><a href="introducción-a-los-procedimientos-de-investigación-en-psicología.html"><i class="fa fa-check"></i><b>1</b> Introducción a los procedimientos de investigación en Psicología</a>
<ul>
<li class="chapter" data-level="1.1" data-path="lógica-de-la-investigación-científica.html"><a href="lógica-de-la-investigación-científica.html"><i class="fa fa-check"></i><b>1.1</b> Lógica de la investigación científica</a></li>
<li class="chapter" data-level="1.2" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html"><i class="fa fa-check"></i><b>1.2</b> Validez de las investigaciones</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-de-las-variables-y-definiciones"><i class="fa fa-check"></i><b>1.2.1</b> Validez de las variables y definiciones</a></li>
<li class="chapter" data-level="1.2.2" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-del-diseño-de-investigación"><i class="fa fa-check"></i><b>1.2.2</b> Validez del diseño de investigación</a></li>
<li class="chapter" data-level="1.2.3" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-de-conclusión-estadística"><i class="fa fa-check"></i><b>1.2.3</b> Validez de conclusión estadística</a></li>
<li class="chapter" data-level="1.2.4" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#contraste-de-hipótesis-estadísticas"><i class="fa fa-check"></i><b>1.2.4</b> Contraste de hipótesis estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="potencia-de-un-contraste.html"><a href="potencia-de-un-contraste.html"><i class="fa fa-check"></i><b>1.3</b> Potencia de un contraste</a></li>
<li class="chapter" data-level="1.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>1.4</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="1.5" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><i class="fa fa-check"></i><b>1.5</b> Contrastes de hipótesis en los programas estadísticos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#contrastes-para-1-variable"><i class="fa fa-check"></i><b>1.5.1</b> Contrastes para 1 variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#contrastes-para-1-vi-cualitativa-y-una-vd-cuantitativa"><i class="fa fa-check"></i><b>1.5.2</b> Contrastes para 1 VI cualitativa y una VD cuantitativa</a></li>
<li class="chapter" data-level="1.5.3" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#pruebas-para-muestras-relacionadas-2-medidas-por-unidad-de-observación"><i class="fa fa-check"></i><b>1.5.3</b> Pruebas para muestras relacionadas (2 medidas por unidad de observación)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-i-diseños-transversales.html"><a href="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-i-diseños-transversales.html"><i class="fa fa-check"></i><b>2</b> Relación entre una variable cualitativa y otra cuantitativa (I): Diseños transversales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="criterios-de-selección-de-la-técnica-estadística.html"><a href="criterios-de-selección-de-la-técnica-estadística.html"><i class="fa fa-check"></i><b>2.1</b> Criterios de selección de la técnica estadística</a></li>
<li class="chapter" data-level="2.2" data-path="anova-de-1-factor-completamente-aleatorizado.html"><a href="anova-de-1-factor-completamente-aleatorizado.html"><i class="fa fa-check"></i><b>2.2</b> ANOVA de 1 factor completamente aleatorizado</a></li>
<li class="chapter" data-level="2.3" data-path="comprobación-de-los-supuestos.html"><a href="comprobación-de-los-supuestos.html"><i class="fa fa-check"></i><b>2.3</b> 3.1. Comprobación de los supuestos</a></li>
<li class="chapter" data-level="2.4" data-path="tamaño-del-efecto-1.html"><a href="tamaño-del-efecto-1.html"><i class="fa fa-check"></i><b>2.4</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="2.5" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html"><i class="fa fa-check"></i><b>2.5</b> Comparaciones a posteriori</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html#criterio-de-bonferroni"><i class="fa fa-check"></i><b>2.5.1</b> Criterio de Bonferroni</a></li>
<li class="chapter" data-level="2.5.2" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html#prueba-de-tukey"><i class="fa fa-check"></i><b>2.5.2</b> Prueba de Tukey</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="comparaciones-de-tendencia.html"><a href="comparaciones-de-tendencia.html"><i class="fa fa-check"></i><b>2.6</b> Comparaciones de tendencia</a></li>
<li class="chapter" data-level="2.7" data-path="prueba-de-brown-forsythe.html"><a href="prueba-de-brown-forsythe.html"><i class="fa fa-check"></i><b>2.7</b> Prueba de Brown-Forsythe</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="prueba-de-brown-forsythe.html"><a href="prueba-de-brown-forsythe.html#comparaciones-a-posteriori-1"><i class="fa fa-check"></i><b>2.7.1</b> Comparaciones a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="prueba-de-kuskal-wallis-kw.html"><a href="prueba-de-kuskal-wallis-kw.html"><i class="fa fa-check"></i><b>2.8</b> Prueba de Kuskal-Wallis (KW)</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="prueba-de-kuskal-wallis-kw.html"><a href="prueba-de-kuskal-wallis-kw.html#comparaciones-a-posteriori-2"><i class="fa fa-check"></i><b>2.8.1</b> Comparaciones a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="anova-de-un-factor-con-jamovi.html"><a href="anova-de-un-factor-con-jamovi.html"><i class="fa fa-check"></i><b>2.9</b> ANOVA de un factor con JAMOVI</a></li>
<li class="chapter" data-level="2.10" data-path="anova-de-un-factor-con-spss.html"><a href="anova-de-un-factor-con-spss.html"><i class="fa fa-check"></i><b>2.10</b> ANOVA de un factor con SPSS</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>3</b> Introducción</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modelo-estadístico.html"><a href="modelo-estadístico.html"><i class="fa fa-check"></i><b>3.1</b> Modelo estadístico</a></li>
<li class="chapter" data-level="3.2" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html"><i class="fa fa-check"></i><b>3.2</b> Interacción entre factores</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html#ejemplo-de-diseño-factorial"><i class="fa fa-check"></i><b>3.2.1</b> Ejemplo de diseño factorial</a></li>
<li class="chapter" data-level="3.2.2" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html#ejemplo-3.2"><i class="fa fa-check"></i><b>3.2.2</b> Ejemplo 3.2</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="a2fc-con-el-programa-spss.html"><a href="a2fc-con-el-programa-spss.html"><i class="fa fa-check"></i><b>3.3</b> A2FC con el programa SPSS</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Diseño y Análisis de datos II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="validez-de-las-investigaciones" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Validez de las investigaciones<a href="validez-de-las-investigaciones.html#validez-de-las-investigaciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La validez de un estudio, depende la naturaleza de las variables y sus definiciones, del diseño de investigación y de la técnica estadística utilizada.</p>
<div id="validez-de-las-variables-y-definiciones" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Validez de las variables y definiciones<a href="validez-de-las-investigaciones.html#validez-de-las-variables-y-definiciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En toda investigación científica se trabaja con conceptos que deben ser <em>operacionalizados</em> para que puedan ser medidos y presenten un significado unívoco. Los problemas de validez surgen cuando las operaciones realizadas no tienen nada que ver con el constructo estudiado o su vinculación es parcial.</p>
<p>Las variables pueden medirse mediante cuatro <em>escalas de medida</em> (nominal, ordinal, intervalo y razón). La elección del tipo de medida determinará el tipo de análisis de los datos. Hay ocasiones en las que se han utilizado los términos de <em>cualitativo</em> y <em>cuantitativo</em> para clasificar los distintos tipos de variables <span class="citation">(<a href="a2fc-con-el-programa-spss.html#ref-ato">Ato &amp; Vallejo, 2007</a>)</span>.</p>
<p>Otra clasificación frecuente en Psicología es la distinción entre <em>variable independiente</em> (VI) o <em>variable predictora</em> (VP), <em>variable dependiente</em> (VD) y <em>variables extrañas</em> (VE). En ocasiones se habla de <em>variable criterio</em> en los contextos en los que no hay manipulación en el diseño de investigación. En estos estudios a la VD también se le denomina <em>variable de respuesta</em> (VR).</p>
</div>
<div id="validez-del-diseño-de-investigación" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Validez del diseño de investigación<a href="validez-de-las-investigaciones.html#validez-del-diseño-de-investigación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Con el diseño tenemos que asegurarnos de que las variables extrañas están debidamente controladas (<em>validez interna</em>). Para ello, resulta conveniente utilizar técnicas de control tales como la manipulación de la VI, la aleatorización, el mantenimiento constante de dichas variables o el control estadístico. Asimismo, es importante considerar la generalización los resultados del estudio a otras situaciones. En este caso, estamos hablando de <strong>validez externa</strong>.</p>
</div>
<div id="validez-de-conclusión-estadística" class="section level3 hasAnchor" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Validez de conclusión estadística<a href="validez-de-las-investigaciones.html#validez-de-conclusión-estadística" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La elección de la técnica estadística también influye en la validez de la investigación. Una técnica mal seleccionada puede llevarnos a sacar conclusiones inadecuadas. Afecta a la determinación de la existencia de covariación entre las variables y a su grado. El procedimiento para obtener conclusiones estadísticas es el <em>contraste de hipótesis</em>. Este procedimiento consiste en la toma de decisiones sobre dos hipótesis rivales y excluyentes en base a la probabilidad calculada en función de la distribución de probabilidad de un estadístico. Más adelante se desarrollará este concepto para su completa comprensión.</p>
<p>Entre los errores que se cometen mediante la contrastación de hipótesis es el considerar que existe relación cuando no existe (<em>error tipo I</em> o riesgo <span class="math inline">\(\alpha\)</span>), o considerar que no existe relación cuando la hay (<em>error tipo II</em> o riesgo <span class="math inline">\(\beta\)</span>). Otro error posible es la sobre-estimación o infraestimación de la relación. Posibles factores que pueden afectar a la conclusión estadística es la baja potencia y la violación de los supuestos. También es importante considerar la magnitud del efecto y la significación práctica y clínica de los resultados.</p>
</div>
<div id="contraste-de-hipótesis-estadísticas" class="section level3 hasAnchor" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Contraste de hipótesis estadísticas<a href="validez-de-las-investigaciones.html#contraste-de-hipótesis-estadísticas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dentro de la inferencia estadística buscamos realizar <em>comparaciones</em> y establecer <em>relaciones</em> mediante la <em>estimación de parámetros</em> y el <em>contraste de hipótesis</em>. El primer procedimiento puede hacerse mediante la estimación <em>puntual</em> o por <em>intervalos</em>. En cambio, el contraste de hipótesis es la toma de decisiones acerca de si un conjunto de datos corrobora una hipótesis. Supone cubrir una serie de etapas:</p>
<ul>
<li><p><strong><em>1) Formulación de las hipótesis:</em></strong> Se plantean la <em>hipótesis nula</em> (<span class="math inline">\(H_0\)</span>) que considera que las variaciones existentes entre las condiciones se debe al azar y la <em>hipótesis alternativa</em> (<span class="math inline">\(H_1\)</span>) que niega la hipótesis nula y considera que las variaciones en una variable están relacionada con los cambios en la otra. Las hipótesis pueden ser <em>bidireccionales</em> (no conocemos el sentido de la relación como por ejemplo <span class="math inline">\(\mu_1 = \mu_2\)</span>) o <em>unilaterales</em> (el investigador plantea donde se encontrarán las diferencias como por ejemplo <span class="math inline">\(\mu_1 \leq \mu_2\)</span> ).</p></li>
<li><p><strong><em>2) Definición del estadístico de contraste:</em></strong> Su cálculo supone la realización de un estudio empírico en el que se ha extraído una muestra aleatoria de la población. Este estadístico debe tener una distribución de probabilidad conocida.</p></li>
<li><p><strong><em>3) Regla de decisión:</em></strong> Se basa en la compatibilidad que existe entre la hipótesis nula y los datos empíricos <span class="citation">(<a href="a2fc-con-el-programa-spss.html#ref-pardo">Pardo &amp; SanMartin, 2010</a>)</span>. Permite determinar la probabilidad de que <span class="math inline">\(H_0\)</span> sea cierta en base a nuestros resultados. Para determinar el grado de apoyo de <span class="math inline">\(H_0\)</span> se divide a la distribución teórica en dos regiones (<em>región de confianza</em> y <em>región crítica</em>). La región de confianza es la zona de la distribución teórica en la que se acepta <span class="math inline">\(H_0\)</span>. Existe consenso en considerar que esta región alcance el 95% de probabilidad. La región crítica es la zona complementaria a la región de confianza (por lo que cubre el 5% de la distribución) y si el estadístico pertenece a esa zona se rechaza <span class="math inline">\(H_0\)</span>. Si la hipótesis es bilateral la región crítica estará ambos lados de la distribución teórica. En cambio, si la hipótesis es unilateral la región de confianza estará situada en una de las colas de las distribución.</p></li>
</ul>
<p><strong><em>Ejemplo 1:</em></strong> A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (<em>fonético</em> versus <em>global</em>). Cada niño sólo fue entrenado con un único método y se quería conocer <strong><em>si había diferencias significativas entre ambos métodos</em></strong>. Nos estamos planteando una hipótesis <strong><em>bidireccional</em></strong>:</p>
<table>
<caption><span id="tab:unnamed-chunk-1">Tabla 1.1: </span>Datos del ejemplo 1</caption>
<tbody>
<tr class="odd">
<td align="left">Fonetico</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left">Global</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">7</td>
<td align="right">8</td>
<td align="right">4</td>
<td align="right">8</td>
</tr>
</tbody>
</table>
<ul>
<li><span class="math inline">\(H_0\)</span>: No hay diferencias en el aprendizaje (<span class="math inline">\(\mu_{F} = \mu_G\)</span>)</li>
<li><span class="math inline">\(H_1\)</span>: El aprendizaje es mejor con el método global (<span class="math inline">\(\mu_{F} \neq \mu_G\)</span>)</li>
</ul>
<p>Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico <em>t</em> de Student:</p>
<p><span class="math display">\[
\bar{Y}_{\bar{Y}_{1} - \bar{Y}_{2}}= \bar{Y}_{1} - \bar{Y}_{2}
\]</span></p>
<p><span class="math display">\[
Var(\bar{Y}_{1} - \bar{Y}_{2}) = \sigma_{1}^{2}/n_{1} + \sigma_{2}^{2}/n_{2}
\]</span></p>
<p><span class="math display">\[
t = \frac{\bar{Y}_{\bar{Y}_{1} - \bar{Y}_{2}}}{Var(\bar{Y}_{1} - \bar{Y}_{2})} \sim t(n-2)
\]</span>
En nuestro caso, el valor del estadístico <em>t</em> vale:</p>
<pre><code>## 
##  Two Sample t-test
## 
## data:  rendimiento by metodo
## t = -2.5955, df = 12, p-value = 0.02342
## alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0
## 95 percent confidence interval:
##  -4.2044435 -0.3669851
## sample estimates:
## mean in group 1 mean in group 2 
##        4.142857        6.428571</code></pre>
<p>Encontramos que el valor de estadístico <em>t</em> vale -2.596 y su valor de probabilidad es 0.023. En base a estos resultados podemos rechazar <span class="math inline">\(H_0\)</span>. Esto significa que el estadístico <em>t</em> se aleja bastante de la predicción establecida mediante la hipótesis nula. Es decir, existe muy poca compatibilidad entre nuestros datos y <span class="math inline">\(H_0\)</span>.</p>
<p>Para aceptar estos resultados debemos confirmar que se cumplen los supuestos de la prueba (normalidad de las muestras y homogeneidad de las varianzas <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>):</p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rendimiento[1:7]
## W = 0.92025, p-value = 0.4713</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rendimiento[8:14]
## W = 0.91511, p-value = 0.4324</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  1    0.06 0.8106
##       12</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Tabla 1.1: </span>Datos del ejemplo 1</caption>
<tbody>
<tr class="odd">
<td align="left">Fonetico</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left">Global</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">7</td>
<td align="right">8</td>
<td align="right">4</td>
<td align="right">8</td>
</tr>
</tbody>
</table>
<ul>
<li><span class="math inline">\(H_0\)</span>: No hay diferencias en el aprendizaje (<span class="math inline">\(\mu_{F} \geq \mu_G\)</span>)</li>
<li><span class="math inline">\(H_1\)</span>: El aprendizaje es mejor con el método global (<span class="math inline">\(\mu_{F} &lt; \mu_G\)</span>)</li>
</ul>
<p>Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico es el mismo y tiene el mismo valor. Sólo cambia su probabilidad:</p>
<pre><code>## 
##  Two Sample t-test
## 
## data:  rendimiento by metodo
## t = -2.5955, df = 12, p-value = 0.01171
## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0
## 95 percent confidence interval:
##        -Inf -0.7161774
## sample estimates:
## mean in group 1 mean in group 2 
##        4.142857        6.428571</code></pre>
<p><strong><em>Ejemplo 2:</em></strong> A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (<em>fonético</em> versus <em>global</em>). Cada niño sólo fue entrenado con un único método y se esperaba encontrar un mayor rendimiento con el método global. Aquí nos planteamos una hipótesis <strong><em>unidireccional</em></strong>:</p>
<table>
<caption><span id="tab:unnamed-chunk-1">Tabla 1.1: </span>Datos del ejemplo 1</caption>
<tbody>
<tr class="odd">
<td align="left">Fonetico</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left">Global</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">7</td>
<td align="right">8</td>
<td align="right">4</td>
<td align="right">8</td>
</tr>
</tbody>
</table>
<ul>
<li><span class="math inline">\(H_0\)</span>: No hay diferencias en el aprendizaje (<span class="math inline">\(\mu_{F} \geq \mu_G\)</span>)</li>
<li><span class="math inline">\(H_1\)</span>: El aprendizaje es mejor con el método global (<span class="math inline">\(\mu_{F} &lt; \mu_G\)</span>)</li>
</ul>
<p>Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico es el mismo y tiene el mismo valor. Sólo cambia su probabilidad:</p>
<pre><code>## 
##  Two Sample t-test
## 
## data:  rendimiento by metodo
## t = -2.5955, df = 12, p-value = 0.01171
## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0
## 95 percent confidence interval:
##        -Inf -0.7161774
## sample estimates:
## mean in group 1 mean in group 2 
##        4.142857        6.428571</code></pre>
<p>Encontramos que el valor de estadístico <em>t</em> vale en este caso <em>t</em> vale -2.596 y su valor de probabilidad es 0.012.</p>
<p><strong><em>Ejemplo 3:</em></strong> Con los mismos datos del ejemplo anterior supongamos que el investigador está interesado en conocer si la media del rendimiento en la población de los estudiantes es 6. Para ello formula las siguientes hipótesis:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{rendimiento}\)</span> = 6</li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\mu_{rendimiento} \neq\)</span> 6</li>
</ul>
<p>Como no conocemos el sentido de la dirección asumimos que la hipótesis es bilateral. Para contrastar esta hipótesis necesitamos conocer si la distribución de la variable sigue una ley normal. En caso de que se cumpla esta hipótesis realizaremos el contraste con la prueba <em>t</em> para una muestra. Si no se cumple, usaremos la <em>prueba de Wilcoxon para una muestra</em>. En este caso, se cumple la normalidad de la variable por lo usamos la prueba <em>t</em>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="validez-de-las-investigaciones.html#cb7-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(rendimiento)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rendimiento
## W = 0.92677, p-value = 0.2747</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="validez-de-las-investigaciones.html#cb9-1" tabindex="-1"></a><span class="fu">t.test</span>(rendimiento)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  rendimiento
## t = 9.9992, df = 13, p-value = 1.801e-07
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  4.143709 6.427720
## sample estimates:
## mean of x 
##  5.285714</code></pre>
<p>Rechazamos la hipótesis de que el valor medio de la variable rendimiento es 6 en la población.</p>
<p><strong><em>Ejemplo 4:</em></strong> Supongamos que construimos un examen para evaluar los conocimientos de los estudiantes de Psicología en la materia de <strong>Diseño y Análisis de Datos II</strong>. El examen tendrá 10 preguntas con 3 opciones de respuesta y solo una correcta. Queremos conocer cuántas preguntas debe responder correctamente el alumno para estar seguros de que sabe y de que no ha respondido por azar. Las hipótesis en este contraste estadístico serán:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: El alumno no sabe por lo que responde al azar (<span class="math inline">\(\pi_{acierto} \leq\)</span> 0.333)</li>
<li><span class="math inline">\(H_1\)</span>: El alumno sabe. No responde al azar (<span class="math inline">\(\pi_{acierto} &gt;\)</span> 0.333)</li>
</ul>
<p>Ahora necesitamos determinar cuántas preguntas suponen responder por azar. Está claro si el alumno acierta sólo 1 pregunta la probabilidad de que haya respondido por azar 0 ó 1 es muy alta. En la siguiente figura se aprecia que los valores más probables están comprendidos entre 2 y 4:</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="_main_files/figure-html/unnamed-chunk-10-1.png" alt="Distribución binomial" width="672" />
<p class="caption">
Figura 1.1: Distribución binomial
</p>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="validez-de-las-investigaciones.html#cb11-1" tabindex="-1"></a><span class="co"># Probabilidad igual a 2:</span></span>
<span id="cb11-2"><a href="validez-de-las-investigaciones.html#cb11-2" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">2</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.1950922</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="validez-de-las-investigaciones.html#cb13-1" tabindex="-1"></a><span class="co"># Probabilidad igual a 3:</span></span>
<span id="cb13-2"><a href="validez-de-las-investigaciones.html#cb13-2" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">3</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.2601229</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="validez-de-las-investigaciones.html#cb15-1" tabindex="-1"></a><span class="co"># Probabilidad igual a 4:</span></span>
<span id="cb15-2"><a href="validez-de-las-investigaciones.html#cb15-2" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">4</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.2276076</code></pre>
<p>Por tanto, necesitamos encontrar el número de preguntas acertadas que tengan una probabilidad de ser acertadas por azar <span class="math inline">\(\leq\)</span> 0,05. Esto se consigue con 6 preguntas acertadas. Con 5 preguntas acertadas estaríamos por encima del nivel de riesgo establecido por convención del 5%:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="validez-de-las-investigaciones.html#cb17-1" tabindex="-1"></a><span class="co"># Probabilidad menor o igual a 6:</span></span>
<span id="cb17-2"><a href="validez-de-las-investigaciones.html#cb17-2" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">6</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<p>[1] 0.9803384</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="validez-de-las-investigaciones.html#cb18-1" tabindex="-1"></a><span class="co"># Probabilidad de la región crítica con 6 preguntas:</span></span>
<span id="cb18-2"><a href="validez-de-las-investigaciones.html#cb18-2" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">6</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<p>[1] 0.01966164</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="validez-de-las-investigaciones.html#cb19-1" tabindex="-1"></a><span class="co"># Probabilidad de la región crítica con 5 preguntas:</span></span>
<span id="cb19-2"><a href="validez-de-las-investigaciones.html#cb19-2" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<p>[1] 0.07656353</p>
<p>No obstante, el criterio de 0,05 es un criterio establecido arbitrariamente y que supone la ausencia de factores contaminantes que estarían actuando en la situación real de examen y que estarían afectando al resultado del examen. Un profesor algo más exigente podría considerar la necesidad de aprobar acertando 7 preguntas. En este caso, la probabilidad de que un estudiante acertara por azar sería:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="validez-de-las-investigaciones.html#cb20-1" tabindex="-1"></a><span class="co"># Probabilidad menor o igual a 7:</span></span>
<span id="cb20-2"><a href="validez-de-las-investigaciones.html#cb20-2" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">7</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<p>[1] 0.996596</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="validez-de-las-investigaciones.html#cb21-1" tabindex="-1"></a><span class="co"># Probabilidad de la región crítica con 7 preguntas:</span></span>
<span id="cb21-2"><a href="validez-de-las-investigaciones.html#cb21-2" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">7</span>,<span class="dv">10</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<p>[1] 0.003403953</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>En este caso no es necesario calcular la normalidad de los errores, ya que si las muestras son normales también serán normales los errores. Esto se verá con más claridad en el próximo tema.<a href="validez-de-las-investigaciones.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lógica-de-la-investigación-científica.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="potencia-de-un-contraste.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-Tema1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
