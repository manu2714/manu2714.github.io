<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.8 Prueba de Kuskal-Wallis (KW) | Análisis de datos en psicología II</title>
  <meta name="description" content="Libro de DAD2" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="2.8 Prueba de Kuskal-Wallis (KW) | Análisis de datos en psicología II" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Libro de DAD2" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.8 Prueba de Kuskal-Wallis (KW) | Análisis de datos en psicología II" />
  
  <meta name="twitter:description" content="Libro de DAD2" />
  

<meta name="author" content="Manuel Morales Ortiz" />


<meta name="date" content="2023-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estadísticos-f-robustos-brown-forsythe-y-welch.html"/>
<link rel="next" href="anova-de-un-factor-con-jamovi.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Análisis de Datos II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="introducción-a-los-procedimientos-de-investigación-en-psicología.html"><a href="introducción-a-los-procedimientos-de-investigación-en-psicología.html"><i class="fa fa-check"></i><b>1</b> Introducción a los procedimientos de investigación en Psicología</a>
<ul>
<li class="chapter" data-level="1.1" data-path="lógica-de-la-investigación-científica.html"><a href="lógica-de-la-investigación-científica.html"><i class="fa fa-check"></i><b>1.1</b> Lógica de la investigación científica</a></li>
<li class="chapter" data-level="1.2" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html"><i class="fa fa-check"></i><b>1.2</b> Validez de las investigaciones</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-de-las-variables-y-definiciones"><i class="fa fa-check"></i><b>1.2.1</b> Validez de las variables y definiciones</a></li>
<li class="chapter" data-level="1.2.2" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-del-diseño-de-investigación"><i class="fa fa-check"></i><b>1.2.2</b> Validez del diseño de investigación</a></li>
<li class="chapter" data-level="1.2.3" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#validez-de-conclusión-estadística"><i class="fa fa-check"></i><b>1.2.3</b> Validez de conclusión estadística</a></li>
<li class="chapter" data-level="1.2.4" data-path="validez-de-las-investigaciones.html"><a href="validez-de-las-investigaciones.html#contraste-de-hipótesis-estadísticas"><i class="fa fa-check"></i><b>1.2.4</b> Contraste de hipótesis estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="potencia-de-un-contraste.html"><a href="potencia-de-un-contraste.html"><i class="fa fa-check"></i><b>1.3</b> Potencia de un contraste</a></li>
<li class="chapter" data-level="1.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>1.4</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="1.5" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><i class="fa fa-check"></i><b>1.5</b> Contrastes de hipótesis en los programas estadísticos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#contrastes-para-1-variable"><i class="fa fa-check"></i><b>1.5.1</b> Contrastes para 1 variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#contrastes-para-1-vi-cualitativa-y-una-vd-cuantitativa"><i class="fa fa-check"></i><b>1.5.2</b> Contrastes para 1 VI cualitativa y una VD cuantitativa</a></li>
<li class="chapter" data-level="1.5.3" data-path="contrastes-de-hipótesis-en-los-programas-estadísticos.html"><a href="contrastes-de-hipótesis-en-los-programas-estadísticos.html#pruebas-para-muestras-relacionadas-2-medidas-por-unidad-de-observación"><i class="fa fa-check"></i><b>1.5.3</b> Pruebas para muestras relacionadas (2 medidas por unidad de observación)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-i-diseños-transversales.html"><a href="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-i-diseños-transversales.html"><i class="fa fa-check"></i><b>2</b> Relación entre una variable cualitativa y otra cuantitativa (I): Diseños transversales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="criterios-de-selección-de-la-técnica-estadística.html"><a href="criterios-de-selección-de-la-técnica-estadística.html"><i class="fa fa-check"></i><b>2.1</b> Criterios de selección de la técnica estadística</a></li>
<li class="chapter" data-level="2.2" data-path="anova-de-1-factor-completamente-aleatorizado.html"><a href="anova-de-1-factor-completamente-aleatorizado.html"><i class="fa fa-check"></i><b>2.2</b> ANOVA de 1 factor completamente aleatorizado</a></li>
<li class="chapter" data-level="2.3" data-path="comprobación-de-los-supuestos.html"><a href="comprobación-de-los-supuestos.html"><i class="fa fa-check"></i><b>2.3</b> Comprobación de los supuestos</a></li>
<li class="chapter" data-level="2.4" data-path="tamaño-del-efecto-1.html"><a href="tamaño-del-efecto-1.html"><i class="fa fa-check"></i><b>2.4</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="2.5" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html"><i class="fa fa-check"></i><b>2.5</b> Comparaciones a posteriori</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html#criterio-de-bonferroni"><i class="fa fa-check"></i><b>2.5.1</b> Criterio de Bonferroni</a></li>
<li class="chapter" data-level="2.5.2" data-path="comparaciones-a-posteriori.html"><a href="comparaciones-a-posteriori.html#prueba-de-tukey"><i class="fa fa-check"></i><b>2.5.2</b> Prueba de Tukey</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="comparaciones-de-tendencia.html"><a href="comparaciones-de-tendencia.html"><i class="fa fa-check"></i><b>2.6</b> Comparaciones de tendencia</a></li>
<li class="chapter" data-level="2.7" data-path="estadísticos-f-robustos-brown-forsythe-y-welch.html"><a href="estadísticos-f-robustos-brown-forsythe-y-welch.html"><i class="fa fa-check"></i><b>2.7</b> Estadísticos F robustos: Brown-Forsythe y Welch</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="estadísticos-f-robustos-brown-forsythe-y-welch.html"><a href="estadísticos-f-robustos-brown-forsythe-y-welch.html#comparaciones-a-posteriori-1"><i class="fa fa-check"></i><b>2.7.1</b> Comparaciones a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="prueba-de-kuskal-wallis-kw.html"><a href="prueba-de-kuskal-wallis-kw.html"><i class="fa fa-check"></i><b>2.8</b> Prueba de Kuskal-Wallis (KW)</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="prueba-de-kuskal-wallis-kw.html"><a href="prueba-de-kuskal-wallis-kw.html#comparaciones-a-posteriori-2"><i class="fa fa-check"></i><b>2.8.1</b> Comparaciones a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="anova-de-un-factor-con-jamovi.html"><a href="anova-de-un-factor-con-jamovi.html"><i class="fa fa-check"></i><b>2.9</b> ANOVA de un factor con JAMOVI</a></li>
<li class="chapter" data-level="2.10" data-path="anova-de-un-factor-con-spss.html"><a href="anova-de-un-factor-con-spss.html"><i class="fa fa-check"></i><b>2.10</b> ANOVA de un factor con SPSS</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-ii-diseños-longitudinales.html"><a href="relación-entre-una-variable-cualitativa-y-otra-cuantitativa-ii-diseños-longitudinales.html"><i class="fa fa-check"></i><b>3</b> Relación entre una variable cualitativa y otra cuantitativa (II): Diseños longitudinales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modelo-anova-1-factor-de-medidas-repetidas-a1mr.html"><a href="modelo-anova-1-factor-de-medidas-repetidas-a1mr.html"><i class="fa fa-check"></i><b>3.1</b> Modelo ANOVA 1 factor de medidas repetidas (A1MR)</a></li>
<li class="chapter" data-level="3.2" data-path="ejemplo-1-de-diseño-unifactorial-de-medidas-repetidas.html"><a href="ejemplo-1-de-diseño-unifactorial-de-medidas-repetidas.html"><i class="fa fa-check"></i><b>3.2</b> Ejemplo 1 de diseño unifactorial de medidas repetidas</a></li>
<li class="chapter" data-level="3.3" data-path="comprobación-de-los-supuestos-1.html"><a href="comprobación-de-los-supuestos-1.html"><i class="fa fa-check"></i><b>3.3</b> Comprobación de los supuestos</a></li>
<li class="chapter" data-level="3.4" data-path="tamaño-del-efecto-2.html"><a href="tamaño-del-efecto-2.html"><i class="fa fa-check"></i><b>3.4</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="3.5" data-path="potencia-de-la-prueba.html"><a href="potencia-de-la-prueba.html"><i class="fa fa-check"></i><b>3.5</b> Potencia de la prueba</a></li>
<li class="chapter" data-level="3.6" data-path="comparaciones-múltiples.html"><a href="comparaciones-múltiples.html"><i class="fa fa-check"></i><b>3.6</b> Comparaciones múltiples</a></li>
<li class="chapter" data-level="3.7" data-path="prueba-de-friedman.html"><a href="prueba-de-friedman.html"><i class="fa fa-check"></i><b>3.7</b> Prueba de Friedman</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="prueba-de-friedman.html"><a href="prueba-de-friedman.html#ejemplo-de-diseño-unifactorial-de-medidas-repetidas-no-paramétrico"><i class="fa fa-check"></i><b>3.7.1</b> Ejemplo de diseño unifactorial de medidas repetidas no paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="modelo-a1fmr-con-el-programa-jamovi.html"><a href="modelo-a1fmr-con-el-programa-jamovi.html"><i class="fa fa-check"></i><b>3.8</b> Modelo A1FMR con el programa JAMOVI</a></li>
<li class="chapter" data-level="3.9" data-path="prueba-de-friedman-con-el-programa-jamovi.html"><a href="prueba-de-friedman-con-el-programa-jamovi.html"><i class="fa fa-check"></i><b>3.9</b> Prueba de Friedman con el programa JAMOVI</a></li>
<li class="chapter" data-level="3.10" data-path="modelo-a1fmr-con-el-programa-spss.html"><a href="modelo-a1fmr-con-el-programa-spss.html"><i class="fa fa-check"></i><b>3.10</b> Modelo A1FMR con el programa SPSS</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="modelo-a1fmr-con-el-programa-spss.html"><a href="modelo-a1fmr-con-el-programa-spss.html#conclusiones-según-normas-apa"><i class="fa fa-check"></i><b>3.10.1</b> Conclusiones según normas APA:</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="prueba-de-friedman-con-el-programa-spss.html"><a href="prueba-de-friedman-con-el-programa-spss.html"><i class="fa fa-check"></i><b>3.11</b> Prueba de Friedman con el programa SPSS</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="prueba-de-friedman-con-el-programa-spss.html"><a href="prueba-de-friedman-con-el-programa-spss.html#conclusiones"><i class="fa fa-check"></i><b>3.11.1</b> Conclusiones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="diseños-factoriales-i-diseño-factorial-completamente-aleatorizado-a2fca.html"><a href="diseños-factoriales-i-diseño-factorial-completamente-aleatorizado-a2fca.html"><i class="fa fa-check"></i><b>4</b> Diseños factoriales (I): Diseño factorial completamente aleatorizado (A2FCA)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="modelo-estadístico.html"><a href="modelo-estadístico.html"><i class="fa fa-check"></i><b>4.1</b> Modelo estadístico</a></li>
<li class="chapter" data-level="4.2" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html"><i class="fa fa-check"></i><b>4.2</b> Interacción entre factores</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html#ejemplo-4.1-de-diseño-factorial"><i class="fa fa-check"></i><b>4.2.1</b> Ejemplo 4.1 de diseño factorial</a></li>
<li class="chapter" data-level="4.2.2" data-path="interacción-entre-factores.html"><a href="interacción-entre-factores.html#ejemplo-4.2-de-diseño-factorial"><i class="fa fa-check"></i><b>4.2.2</b> Ejemplo 4.2 de diseño factorial</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="a2fc-con-el-programa-jamovi.html"><a href="a2fc-con-el-programa-jamovi.html"><i class="fa fa-check"></i><b>4.3</b> A2FC con el programa JAMOVI</a></li>
<li class="chapter" data-level="4.4" data-path="a2fc-con-el-programa-spss.html"><a href="a2fc-con-el-programa-spss.html"><i class="fa fa-check"></i><b>4.4</b> A2FC con el programa SPSS</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="diseños-factoriales-ii-diseño-factorial-con-medidas-repetidas-a2fmr-y-a2fmx.html"><a href="diseños-factoriales-ii-diseño-factorial-con-medidas-repetidas-a2fmr-y-a2fmx.html"><i class="fa fa-check"></i><b>5</b> Diseños factoriales (II): Diseño factorial con medidas repetidas (A2FMR y A2FMX)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="diseño-factorial-intrasujeto.html"><a href="diseño-factorial-intrasujeto.html"><i class="fa fa-check"></i><b>5.1</b> Diseño factorial intrasujeto</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="diseño-factorial-intrasujeto.html"><a href="diseño-factorial-intrasujeto.html#ejemplo-1-diseño-factorial-de-medidas-repetidas"><i class="fa fa-check"></i><b>5.1.1</b> Ejemplo 1: Diseño factorial de medidas repetidas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="diseño-factorial-mixto-a2fmx.html"><a href="diseño-factorial-mixto-a2fmx.html"><i class="fa fa-check"></i><b>5.2</b> Diseño factorial mixto (A2FMX)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="diseño-factorial-mixto-a2fmx.html"><a href="diseño-factorial-mixto-a2fmx.html#ejemplo-2-diseño-factorial-mixto"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo 2: Diseño factorial mixto</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="análisis-de-los-ejemplos-con-spss.html"><a href="análisis-de-los-ejemplos-con-spss.html"><i class="fa fa-check"></i><b>5.3</b> Análisis de los ejemplos con SPSS</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="análisis-de-los-ejemplos-con-spss.html"><a href="análisis-de-los-ejemplos-con-spss.html#análisis-del-ejemplo-5.1-con-spss"><i class="fa fa-check"></i><b>5.3.1</b> Análisis del ejemplo 5.1 con SPSS</a></li>
<li class="chapter" data-level="5.3.2" data-path="análisis-de-los-ejemplos-con-spss.html"><a href="análisis-de-los-ejemplos-con-spss.html#análisis-del-ejemplo-5.2-con-spss"><i class="fa fa-check"></i><b>5.3.2</b> Análisis del ejemplo 5.2 con SPSS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-de-regresión-lineal.html"><a href="modelos-de-regresión-lineal.html"><i class="fa fa-check"></i><b>6</b> Modelos de regresión lineal</a>
<ul>
<li class="chapter" data-level="6.1" data-path="correlación.html"><a href="correlación.html"><i class="fa fa-check"></i><b>6.1</b> Correlación</a></li>
<li class="chapter" data-level="6.2" data-path="regresión-simple.html"><a href="regresión-simple.html"><i class="fa fa-check"></i><b>6.2</b> Regresión simple</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="regresión-simple.html"><a href="regresión-simple.html#predictores-categóricos"><i class="fa fa-check"></i><b>6.2.1</b> Predictores categóricos</a></li>
<li class="chapter" data-level="6.2.2" data-path="regresión-simple.html"><a href="regresión-simple.html#realización-de-pronósticos"><i class="fa fa-check"></i><b>6.2.2</b> Realización de pronósticos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html"><i class="fa fa-check"></i><b>6.3</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#selección-de-modelos"><i class="fa fa-check"></i><b>6.3.1</b> Selección de modelos</a></li>
<li class="chapter" data-level="6.3.2" data-path="regresión-lineal-múltiple.html"><a href="regresión-lineal-múltiple.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>6.3.2</b> Importancia de las variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="supuestos-del-modelo.html"><a href="supuestos-del-modelo.html"><i class="fa fa-check"></i><b>6.4</b> Supuestos del modelo</a></li>
<li class="chapter" data-level="6.5" data-path="regresión-múltiple-y-modelos-estadísticos.html"><a href="regresión-múltiple-y-modelos-estadísticos.html"><i class="fa fa-check"></i><b>6.5</b> Regresión múltiple y modelos estadísticos</a></li>
<li class="chapter" data-level="6.6" data-path="análisis-de-regresión-mediante-el-programa-jamovi.html"><a href="análisis-de-regresión-mediante-el-programa-jamovi.html"><i class="fa fa-check"></i><b>6.6</b> Análisis de regresión mediante el programa JAMOVI</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="análisis-de-regresión-mediante-el-programa-jamovi.html"><a href="análisis-de-regresión-mediante-el-programa-jamovi.html#regresión-lineal-múltiple-1"><i class="fa fa-check"></i><b>6.6.1</b> Regresión lineal múltiple</a></li>
<li class="chapter" data-level="6.6.2" data-path="análisis-de-regresión-mediante-el-programa-jamovi.html"><a href="análisis-de-regresión-mediante-el-programa-jamovi.html#modelo-de-moderación-con-jamovi"><i class="fa fa-check"></i><b>6.6.2</b> Modelo de moderación con JAMOVI</a></li>
<li class="chapter" data-level="6.6.3" data-path="análisis-de-regresión-mediante-el-programa-jamovi.html"><a href="análisis-de-regresión-mediante-el-programa-jamovi.html#modelos-de-mediación"><i class="fa fa-check"></i><b>6.6.3</b> Modelos de mediación</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="análisis-de-regresión-mediante-el-programa-spss.html"><a href="análisis-de-regresión-mediante-el-programa-spss.html"><i class="fa fa-check"></i><b>6.7</b> Análisis de regresión mediante el programa SPSS</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="análisis-de-regresión-mediante-el-programa-spss.html"><a href="análisis-de-regresión-mediante-el-programa-spss.html#selección-de-modelos-en-el-programa-spss"><i class="fa fa-check"></i><b>6.7.1</b> Selección de modelos en el programa SPSS</a></li>
<li class="chapter" data-level="6.7.2" data-path="análisis-de-regresión-mediante-el-programa-spss.html"><a href="análisis-de-regresión-mediante-el-programa-spss.html#modelos-de-moderación-y-mediación-con-el-módulo-de-process-hayes"><i class="fa fa-check"></i><b>6.7.2</b> Modelos de moderación y mediación con el módulo de PROCESS <span class="citation">(Hayes, 2013)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i><b>7</b> Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Análisis de datos en psicología II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prueba-de-kuskal-wallis-kw" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Prueba de Kuskal-Wallis (KW)<a href="prueba-de-kuskal-wallis-kw.html#prueba-de-kuskal-wallis-kw" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Esta prueba no necesita que se cumplan los supuestos de normalidad y homogeneidad propias del ANOVA. Además, puede utilizarse cuando los datos son de tipo ordinal. Este método pretende contrastar la hipótesis de que <em>J</em> muestras aleatorias independientes proceden de la misma población (o de distintas poblaciones). Para ello, se asignan rangos desde 1 hasta N al conjunto de las <span class="math inline">\(Y_{ij}\)</span> observaciones del diseño como si fuera un única muestra (si hay empates se aplica el promedio de los rangos implicados). Al final se obtiene un rango <span class="math inline">\(R_{ij}\)</span> para cada una de las observaciones.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-46"></span>
<img src="figurasR/kw1c.png" alt="Esquema del diseño para la prueba de Kruskall-Wallis" width="70%" />
<p class="caption">
Figura 2.4: Esquema del diseño para la prueba de Kruskall-Wallis
</p>
</div>
<p>El estadístico H de Kruskal-Wallis viene definido de la siguiente forma:</p>
<p><span class="math display">\[
H = \frac{12}{N(N+1)}\sum_{j=1}^{J}\frac{R_j}{n_j} - 3(N - 1)
\]</span></p>
<p>Bajo la hipótesis nula de que las <em>J</em> poblaciones tienen la misma forma, el estadístico H se distribuye según un modelo de probabilidad <em>ji-cuadrado</em> con <em>J - 1</em> grados de libertad. El rechazo de esta hipótesis supone que los <em>J</em> promedios comparados no son iguales.</p>
<p><em>Ejemplo 2.2:</em></p>
<p>Supongamos que estamos interesados en el estudio de los 3 métodos de enseñanza para mejorar el rendimiento de los escolares. Los resultados fueron los siguientes:</p>
<table>
<caption>
<span id="tab:Ej2">Tabla 2.4: </span>Datos del ejemplo 2.2
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
A
</th>
<th style="text-align:right;">
B
</th>
<th style="text-align:right;">
C
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
s1
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
s2
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
s3
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
18
</td>
</tr>
<tr>
<td style="text-align:left;">
s4
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
s5
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
12
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-47"></span>
<img src="figurasR/boxplot22.png" alt="Boxplot del ejemplo  2.2" width="80%" />
<p class="caption">
Figura 2.5: Boxplot del ejemplo 2.2
</p>
</div>
<p>Observamos que los grupos son bastante asimétricos. En particular, se tiene que el grupo B muestra una distribución muy alejada de la normalidad. Esto puede comprobarse mediante el estadístico de Shapiro-Wilk:</p>
<p><em>Media del grupo A:</em></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  aciertos2[1:5]
## W = 0.94691, p-value = 0.7151</code></pre>
<p><em>Media del grupo B:</em></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  aciertos2[6:10]
## W = 0.64863, p-value = 0.002565</code></pre>
<p><em>Media del grupo C:</em></p>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  aciertos2[11:15]
## W = 0.82664, p-value = 0.1313</code></pre>
<p>En este caso es adecuado aplicar el estadístico de Kruskal- Wallis.</p>
<pre><code>Kruskal-Wallis rank sum test</code></pre>
<p>data: aciertos2 by grupo
Kruskal-Wallis chi-squared = 7.6473, df = 2, p-value = 0.02185</p>
<table>
<caption>
<span id="tab:unnamed-chunk-51">Tabla 2.5: </span>Rangos del ejemplo 2.2
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
A
</th>
<th style="text-align:right;">
B
</th>
<th style="text-align:right;">
C
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
s1
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
10.5
</td>
<td style="text-align:right;">
3.5
</td>
</tr>
<tr>
<td style="text-align:left;">
s2
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
1.0
</td>
<td style="text-align:right;">
3.5
</td>
</tr>
<tr>
<td style="text-align:left;">
s3
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
10.5
</td>
<td style="text-align:right;">
7.0
</td>
</tr>
<tr>
<td style="text-align:left;">
s4
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
9.0
</td>
<td style="text-align:right;">
2.0
</td>
</tr>
<tr>
<td style="text-align:left;">
s5
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
8.0
</td>
<td style="text-align:right;">
5.0
</td>
</tr>
</tbody>
</table>
<p>En la tabla 2.5 aparece el rango para cada una de las puntuaciones. Calculando las medias de los rangos de cada uno de los grupos observamos que las menores puntuaciones están en el grupo C seguido del grupo B:</p>
<p><em>Media del grupo A:</em></p>
<pre><code>## [1] 12</code></pre>
<p><em>Media del grupo B:</em></p>
<pre><code>## [1] 7.8</code></pre>
<p><em>Media del grupo C:</em></p>
<pre><code>## [1] 4.2</code></pre>
<p>Al igual que en el caso del ANOVA, para conocer cuáles son las diferencias significativas entre los grupos será necesario realizar una prueba <em>post-hoc</em>.</p>
<div id="comparaciones-a-posteriori-2" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> Comparaciones a posteriori<a href="prueba-de-kuskal-wallis-kw.html#comparaciones-a-posteriori-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando no se cumplen los supuestos de aplicación del ANOVA las comparaciones a posteriori se pueden realizar mediante la técnica <em>U de Mann-Whitney</em> (MW)<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Esta prueba sirve, al igual que la prueba T de Student para comparar dos muestras independientes. Resulta útil cuando no se cumple la hipótesis de normalidad o los datos son ordinales.</p>
<p>Sean dos muestras aleatorias de tamaño <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span>. Sea <span class="math inline">\(R_{i}\)</span> el rango asignado a cada una de las puntuaciones cuando se toman todas en conjunto como si fuera una única muestra. A continuación, se calculan los siguientes estadísticos <span class="math inline">\(S_1\)</span> y <span class="math inline">\(S_2\)</span> que corresponden a la suma de los rangos de las observaciones del grupo 1 y grupo 2 respectivamente:</p>
<p><span class="math display">\[
S_1 = \sum_{i=1}^{n_1}R_{i1} \qquad y \qquad S_2 = \sum_{i=1}^{n_2}R_{i2}
\]</span>
Se verifica que la suma de los N rangos vale <span class="citation">(<a href="referencias.html#ref-pardo">Pardo &amp; San Martin, 2010</a>)</span>:</p>
<p><span class="math display">\[
S_1 + S_2 = \frac{N(N+1)}{2}
\]</span></p>
<p>Si se asume que las dos muestras proceden de la misma población cabe esperar que <span class="math inline">\(S_1\)</span> y <span class="math inline">\(S_2\)</span> sean iguales o parecidos y que solo muestren pequeñas variaciones debidas al azar. Por tanto, el estadístico U sería cualquiera de los dos sumandos. Por ejemplo, U = <span class="math inline">\(S_1\)</span>.</p>
<p>Una vez definido el estadístico, el paso siguiente es determinar su distribución de probabilidad. Esta distribución no es muy complicada en el caso de que tengamos pocos valores y podremos calcular el valor de probabilidad exacto. Cuando el número de valores es relativamente grande será necesario realizar la siguiente aproximación:</p>
<p><span class="math display">\[
Z = \frac{U - \mu_U}{\sigma_U} \qquad donde \qquad \mu_U = \frac{n_1(N+1)}{2} \qquad y \qquad  \sigma_U = \sqrt{n_1n_2(N+1)/12}
\]</span>
<em>Ejemplo</em></p>
<p>En el ejemplo 2.2 que se estudió cuando se introdujo la técnicas KW encontramos que había diferencias significativas por lo que será necesario determinar las diferencias entre los distintos métodos de enseñanza. Necesitamos determinar que métodos son los que muestran diferencias significativas:</p>
<p><em>Prueba de U de Mann-whitney para métodos A y B:</em></p>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  b[1:5] and b[6:10]
## W = 21, p-value = 0.09369
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p><em>Tamaño del efecto para métodos A y B:</em></p>
<pre><code>## 
## Cliff&#39;s Delta
## 
## delta estimate: 0.68 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.2847567  0.9604032</code></pre>
<p><em>Prueba de U de Mann-whitney para métodos A y C:</em></p>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  b[1:5] and b[11:15]
## W = 24, p-value = 0.02118
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p><em>Tamaño del efecto para métodos A y C:</em></p>
<pre><code>## 
## Cliff&#39;s Delta
## 
## delta estimate: 0.92 (large)
## 95 percent confidence interval:
##     lower     upper 
## 0.5171092 0.9891504</code></pre>
<p><em>Prueba de U de Mann-whitney para métodos B y C:</em></p>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  b[6:10] and b[11:15]
## W = 20, p-value = 0.1412
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p><em>Tamaño del efecto para métodos B y C:</em></p>
<pre><code>## 
## Cliff&#39;s Delta
## 
## delta estimate: 0.6 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.4370519  0.9522030</code></pre>
<p>Si consideramos un criterio de significación <span class="math inline">\(\alpha\)</span> = 0,05 tenemos que corregir el azar debido a que hemos realizado más de un test. Aplicando el criterio de Bonferroni (<span class="math inline">\(\alpha_C\)</span> = 0,05/3 = 0.0167) concluimos que no hay ninguna diferencia significativa. La misma conclusión obtendríamos si aplicáramos la corrección de Sidak (<span class="math inline">\(\alpha_C\)</span> = 0,017).</p>
<p>El problema de utilizar la prueba de U de Mann-Whitney para realizar las comparaciones a posteriori es que no se mantienen los rangos del conjunto de observaciones, produciéndose un reajuste de los rangos en cada una de las comparaciones dos a dos. Existen varias alternativas a este procedimiento como la prueba de Dunn, la de Conover, el test de Nemenyi o la prueba de Dwass-Steel-Critchlow-Fligner (DSCF). En el programa de JAMOVI las comparaciones a posteriori se realizan mediante la prueba de DSCF. Se considera que un contraste es significativo si satisface:</p>
<p><span class="math display">\[
W_j = -\frac{n_i(ni+n_j+1)}{2}/\frac{n_in_j}{24}\times \Lambda &gt; q_{\alpha,k}, \quad \text{para} \quad 1\leq i\leq j\leq k
\]</span></p>
<p>donde:</p>
<p><span class="math display">\[
\Lambda = n_i+n_j -1-\frac{\sum_{b=1}^{g_{ij}}{(t_{b}-1)tb(t_{b}+1)}}{(n_i +n_j)(n_i+n_j -1)}
\]</span></p>
<p><span class="math inline">\(q_{\alpha,k}\)</span> es una cuantila de la distribución normal de los rangos para <em>k</em> grupos, <span class="math inline">\(n_i\)</span> es el número de sujetos del <em>i-ésimo</em> grupo, <span class="math inline">\(n_j\)</span> es el número de sujetos del <em>j-ésimo</em> grupo, <span class="math inline">\(t_b\)</span> es el número de ocurrencias en el rango <em>b</em> y <span class="math inline">\(W_{ij}\)</span> es la suma de los rangos para el <em>i-ésimo</em> grupo donde los rangos se han comparado con el grupo <em>j</em>. Los resultados de aplicar esta prueba aparecen a continuación. Encontramos que sólo aparecen diferencias entre los grupos A y C.</p>
<pre><code>##   A     B    
## B 0.176 -    
## C 0.042 0.256</code></pre>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>JAMOVI utiliza la prueba de Dwass-Steel-Critchlow-Fligner<a href="prueba-de-kuskal-wallis-kw.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estadísticos-f-robustos-brown-forsythe-y-welch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="anova-de-un-factor-con-jamovi.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/02-Tema2.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
